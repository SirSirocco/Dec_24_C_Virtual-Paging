# Dec_24_C_Virtual-Paging

[üáßüá∑ Leia em Portugu√™s](#portugu√™s) | [üá∫üá∏ Read in English](#english)

## Portugu√™s

**Data:** Dezembro, 2024

**Autores:**

- Guilherme Riechert Senko
- Pedro Barizon

## Simulador de mem√≥ria virtual

### Resumo do projeto

Este projeto visa implementar e avaliar um simulador de mem√≥ria virtual, cujo objetivo principal √© explorar o desempenho de quatro algoritmos de substitui√ß√£o de p√°ginas em diferentes cen√°rios. Os algoritmos analisados s√£o:

- _Least Recently Used_ (LRU);
- FIFO Segunda Chance (SC);
- _Not Recently Used_ (NRU);
- Algoritmo √ìtimo (_Optimal_).

### Arquitetura

O simulador foi arquitetado em tr√™s m√≥dulos, cada um com uma fun√ß√£o espec√≠fica:

- **`sim_virtual.c`:** Executa a simula√ß√£o, processando os acessos √† mem√≥ria a partir de um arquivo _log_ de entrada. Este m√≥dulo calcula as m√©tricas de n√∫mero de faltas de p√°gina (_page faults_) e de p√°ginas escritas em disco (_page writes_), baseando-se nos _status_ das p√°ginas durante a execu√ß√£o dos algoritmos.
- **`virtual_mem.c`:** Implementa as estruturas de dados essenciais para a simula√ß√£o. O principal componente √© uma lista simplesmente encadeada com ponteiros para o in√≠cio e para o final, chamada `PageList`, de maneira a permitir f√°cil manipula√ß√£o das p√°ginas pelos algoritmos, que podem se utilizar da lista como uma fila com varia√ß√µes.
- **`subs_method.c`:** Define as rotinas espec√≠ficas para cada algoritmo de substitui√ß√£o de p√°gina. Cada algoritmo √© composto por tr√™s fun√ß√µes principais:
  - `add`: Insere uma nova p√°gina na estrutura.
  - `subs`: Remove a p√°gina de acordo com a pol√≠tica do algoritmo.
  - `update`: Atualiza os atributos da p√°gina quando esta √© referenciada quando j√° est√° alocada em mem√≥ria.

### Implementa√ß√£o dos algoritmos

Dada uma nova refer√™ncia de p√°gina, existem tr√™s condi√ß√µes poss√≠veis:

1. A p√°gina j√° est√° em `page_list`.
2. A p√°gina n√£o est√° em `page_list`:
   a. E o n√∫mero de entradas de `page_list` √© menor que `entry_max`.
   b. E o n√∫mero de entradas de `page_list` √© igual a `entry_max`.

#### _Least Recently Used_ (LRU)

O algoritmo LRU substitui a p√°gina que n√£o foi utilizada h√° mais tempo. Define-se uma estrutura de fila, chamada `page_list`, com um certo limite de elementos, chamado `entry_max`. A ideia √© que as p√°ginas mais recentemente referenciadas fiquem ao final da fila. Assim, removendo-se do in√≠cio, retiram-se sempre as p√°ginas menos recentemente utilizadas (_Least Recently Used_). Diante disso:

- Se ocorrer 1:
  Remove a p√°gina atual de `page_list`, atualiza seus atributos, e reinsere ao final da fila. Afinal, como a p√°gina foi referenciada por √∫ltimo, deve figurar no fim.
- Se ocorrer 2.a:
  Apenas insere a p√°gina no fim da fila, pelo mesmo motivo da situa√ß√£o 1.
- Se ocorrer 2.b:
  Remove a p√°gina _Least Recenty Used_, isto √©, a p√°gina no in√≠cio da fila. Insere a nova p√°gina ao final.

#### FIFO Segunda Chance (SC)

Define-se uma estrutura de fila, chamada `page_list`, com um certo limite de elementos, chamado `entry_max`. Cada p√°gina possui uma _flag_ chamada `referenced`, que indica se esta foi recentemente referenciada. A ideia √© que sejam removidas as p√°ginas mais antigas, isto √©, aquelas que tenham entrado na fila primeiro ‚Äî ficando, portanto, ao in√≠cio. H√°, por√©m, um detalhe: partindo-se do in√≠cio da fila, ao se tentar remover uma p√°gina, se a _flag_ `referenced` estiver ativa, √© dada uma segunda chance, desativando-se a _flag_ da p√°gina atual e passando-se para a pr√≥xima. Caso todas as p√°ginas sejam percorridas, retorna-se o primeiro elemento da fila, emulando-se uma fila circular. Diante disso:

- Se ocorrer 1:
  Ativa `referenced` da p√°gina referenciada, mas n√£o altera sua posi√ß√£o na fila.
- Se ocorrer 2.a:
  Apenas insere a p√°gina no fim da fila, com a _flag_ `referenced` ativada.
- Se ocorrer 2.b:
  Aplica o procedimento descrito no par√°grafo anterior, removendo a p√°gina mais antiga que n√£o tem segunda chance.

#### _Not Recently Used_ (NRU)

Define-se uma estrutura de fila, chamada `page_list`, com um certo limite de elementos, chamado `entry_max`. Cada p√°gina possui uma _flag_ chamada `referenced`, que indica se esta foi recentemente referenciada, e outra, chamada `modified`, que indica modifica√ß√£o da p√°gina. Define-se a fun√ß√£o de prioridade NRU como:

$ p(M, R) = M + 2R $,

em que M √© a `modified`; e R, `referenced`. Se estiverem ativadas, possuem valor 1. Do contr√°rio, 0. Isso determina quatro classes de p√°ginas:

| Classe                            | Prioridade |
| --------------------------------- | ---------- |
| Referenciada e modificada         | 3          |
| Referenciada e n√£o modificada     | 2          |
| N√£o referenciada e modificada     | 1          |
| N√£o referenciada e n√£o modificada | 0          |

A ideia √© que as p√°ginas de `page_list` sejam ordenadas crescentemente segundo a fun√ß√£o de prioridade $p$, de modo que as de menor prioridade fiquem ao in√≠cio da fila. Em caso de empate, arbitra-se a ado√ß√£o do crit√©rio LRU: a mais recentemente utilizada ter√° maior prioridade. Tal escolha √© baseada no **Princ√≠pio da Localidade Temporal**.

Al√©m disso, define-se uma rotina de desativa√ß√£o das _flags_ de refer√™ncia, a fim de trazer dinamismo √† fila. Assim, arbitra-se que, ap√≥s `entry_max` novas refer√™ncias, todas as _flags_ referenced s√£o desativadas. Diante disso:

- Se ocorrer 1:
  Remove p√°gina atual da fila e atualiza seus atributos. Incrementa o contador de refer√™ncias. Se necess√°rio, executa a rotina de desativa√ß√£o de _flags_ `referenced`, reordena a fila e reinicia o contador. Reinsere de forma ordenada a p√°gina atual.
- Se ocorrer 2.a:
  Incrementa o contador de refer√™ncias. Se necess√°rio, executa a rotina de desativa√ß√£o de _flags_ `referenced`, reordena a fila e reinicia o contador. Insere de forma ordenada a p√°gina atual.
- Se ocorrer 2.b:
  Incrementa o contador de refer√™ncias. Se necess√°rio, executa a rotina de desativa√ß√£o de _flags_ `referenced`, reordena a fila e reinicia o contador. Remove o primeiro elemento da fila. Insere de forma ordenada a nova p√°gina.

#### Algoritmo √ìtimo (_Optimal_)

Remove a p√°gina referenciada no futuro mais distante.

Define-se uma estrutura de fila, chamada `page_list`, com um certo limite de elementos, chamado `entry_max`. Cada p√°gina possui uma entrada chamada `next_ref`, que indica a pr√≥xima linha em que a p√°gina √© referenciada no arquivo `file` de endere√ßos virtuais. Caso n√£o haja mais refer√™ncias, define-se a constante simb√≥lica `PINF` (_Page Index Not Found_) como o maior valor represent√°vel por um inteiro sem sinal, que se sup√µe maior que o n√∫mero de linhas de file. A ideia √© que, toda vez que uma p√°gina for referenciada, `file` continue sendo percorrido at√© que encontre a pr√≥xima linha de refer√™ncia, retornando, em seguida, √† posi√ß√£o original.

Assim, ordenam-se as p√°ginas decrescentemente pelo n√∫mero da linha da pr√≥xima refer√™ncia. Dessa forma, as p√°ginas referenciadas no futuro mais distante ficam ao in√≠cio, de modo que a substitui√ß√£o se limite √† remo√ß√£o do primeiro elemento. Caso uma p√°gina j√° na fila seja referenciada, basta remov√™-la, atualizar sua `next_ref` e reinseri-la ordenadamente.

Por fim, vale mencionar que, caso duas ou mais p√°ginas n√£o possuam mais refer√™ncia, o algoritmo remover√° primeiro as que n√£o tiverem sido modificadas, para reduzir o n√∫mero de escritas em disco. Diante disso:

- Se ocorrer 1:
  Remove a p√°gina, atualiza sua `next_ref` e seus outros atributos, e reinsere ordenadamente.
- Se ocorrer 2.a:
  Obtida a `next_ref`, apenas insere a p√°gina ordenadamente.
- Se ocorrer 2.b:
  Remove a primeira p√°gina da fila e insere a nova p√°gina ordenadamente.

### Testes

Os testes foram realizados com quatro arquivos `.log` de entrada simulando diferentes padr√µes de acesso. Al√©m disso, variaram-se o tamanho das p√°ginas (ora 8 kB, ora 32 kB) e o da mem√≥ria princial (1 MB, ora 2 MB). Foi gerado um total de 32 [gr√°ficos](https://docs.google.com/spreadsheets/d/1HnZrXXxIdN1HFNX85y-cW_JEE9XiMo_xyHprkrHulz0/edit?usp=sharing).

### Observa√ß√µes e conclus√µes

A partir dos gr√°ficos, observa-se que o aumento no tamanho das p√°ginas tende a aumentar o n√∫mero de _page faults_, uma vez que se reduz o n√∫mero m√°ximo de p√°ginas em mem√≥ria. Por racioc√≠nio an√°logo, percebe-se que um aumento no tamanho da mem√≥ria principal mantendo fixo o tamanho das p√°ginas tende a reduzir o n√∫mero de faltas de p√°gina.

Quanto ao desempenho dos algoritmos, verifica-se que, obviamente, o √ìtimo sempre resultou no menor n√∫mero de faltas de p√°ginas, mas, surpreendentemente, tamb√©m no menor n√∫mero de p√°ginas escritas. Este √∫ltimo fato se deve √† otimiza√ß√£o implementada quanto √† substitui√ß√£o de p√°ginas sujas. Em seguida, o LRU parece ter gerado o segundo menor n√∫mero de _page faults_, com o NRU logo atr√°s. Quanto √† escrita de p√°ginas, a situa√ß√£o se inverte entre os dois. Afinal, o NRU possui otimiza√ß√µes que objetivam evitar a escrita de p√°ginas modificadas. Por outro lado, vale mencionar que se ter usado o crit√©rio LRU como desempatador do NRU fez com que as faltas de p√°ginas de ambos os algoritmos fossem pr√≥ximas em todas as situa√ß√µes. Por fim, ve-se que o FIFO Segunda Chance apresentou os piores resultados em todos os quesitos, o que aponta para a inefic√°cia da pol√≠tica FIFO.

Em face do exposto, para estudos futuros, sugere-se explorar algoritmos h√≠bridos ou adaptativos que combinem os pontos fortes das abordagens analisadas.

## English

**Date:** December, 2024

**Authors:**

- Guilherme Riechert Senko
- Pedro Barizon

## Virtual Memory Simulator

### Project Summary

This project aims to implement and evaluate a virtual memory simulator, with the main objective of exploring the performance of four page replacement algorithms in different scenarios. The algorithms analyzed are:

- Least Recently Used (LRU);
- FIFO Second Chance (SC);
- Not Recently Used (NRU);
- Optimal Algorithm (Optimal).

### Architecture

The simulator is structured in three modules, each with a specific function:

- **`sim_virtual.c`:** Runs the simulation, processing memory accesses from an input log file. This module calculates metrics such as number of page faults and pages written, based on the status of pages during the execution of the algorithms.
- **`virtual_mem.c`:** Implements the essential data structures for the simulation. The main component is a singly linked list with pointers to the beginning and end, called `PageList`, which allows easy manipulation of pages by the algorithms, enabling them to treat the list as a queue with variations.
- **`subs_method.c`:** Defines the routines specific to each page replacement algorithm. Each algorithm consists of three main functions:
  - `add`: Inserts a new page into the structure.
  - `subs`: Removes the page according to the algorithm's policy.
  - `update`: Updates the page's attributes when it is referenced while already allocated in memory.

### Algorithm Implementation

Given a new page reference, there are three possible conditions:

1. The page is already in `page_list`.
2. The page is not in `page_list`:
   a. And the number of entries in `page_list` is less than `entry_max`.
   b. And the number of entries in `page_list` equals `entry_max`.

#### Least Recently Used (LRU)

The LRU algorithm replaces the page that has not been used for the longest time. A queue structure, called `page_list`, is defined with a certain limit of elements, called `entry_max`. The idea is that the most recently referenced pages are at the end of the queue. Thus, removing from the front always removes the least recently used pages. In this case:

- If condition 1 occurs:
  Removes the current page from `page_list`, updates its attributes, and reinserts it at the end of the queue. Since the page was referenced last, it should be at the end.
- If condition 2.a occurs:
  Simply inserts the page at the end of the queue, for the same reason as condition 1.
- If condition 2.b occurs:
  Removes the Least Recently Used page, which is the page at the front of the queue. Inserts the new page at the end.

#### FIFO Second Chance (SC)

A queue structure, called `page_list`, is defined with a certain limit of elements, called `entry_max`. Each page has a flag called `referenced`, which indicates whether it has been recently referenced. The idea is to remove the oldest pages, i.e., those that entered the queue first ‚Äî therefore, they are at the front. However, there is a detail: starting from the front of the queue, when attempting to remove a page, if the `referenced` flag is active, it gets a second chance, the flag of the current page is deactivated, and the process moves to the next page. If all pages are traversed, the first element in the queue is returned, emulating a circular queue. In this case:

- If condition 1 occurs:
  Activates the `referenced` flag of the referenced page but does not change its position in the queue.
- If condition 2.a occurs:
  Simply inserts the page at the end of the queue, with the `referenced` flag activated.
- If condition 2.b occurs:
  Applies the procedure described in the previous paragraph, removing the oldest page that does not have a second chance.

#### Not Recently Used (NRU)

A queue structure, called `page_list`, is defined with a certain limit of elements, called `entry_max`. Each page has a flag called `referenced`, which indicates whether it has been recently referenced, and another called `modified`, which indicates if the page was modified. The NRU priority function is defined as:

$ p(M, R) = M + 2R $,

where M is `modified`, and R is `referenced`. If both are active, they have a value of 1. Otherwise, they have a value of 0. This determines four classes of pages:

| Class                           | Priority |
| ------------------------------- | -------- |
| Referenced and modified         | 3        |
| Referenced and not modified     | 2        |
| Not referenced and modified     | 1        |
| Not referenced and not modified | 0        |

The idea is to sort the pages in `page_list` in increasing order according to the priority function $p$, so that the lowest priority pages are at the front of the queue. In case of a tie, the LRU criterion is used: the most recently used page has higher priority. This choice is based on the **Principle of Temporal Locality**.

Additionally, a routine to deactivate the reference flags is defined to bring dynamism to the queue. It is assumed that after `entry_max` new references, all the `referenced` flags are deactivated. In this case:

- If condition 1 occurs:
  Removes the current page from the queue and updates its attributes. Increments the reference counter. If necessary, executes the routine to deactivate the `referenced` flags, reorders the queue, and resets the counter. Re-inserts the current page in sorted order.
- If condition 2.a occurs:
  Increments the reference counter. If necessary, executes the routine to deactivate the `referenced` flags, reorders the queue, and resets the counter. Inserts the current page in sorted order.
- If condition 2.b occurs:
  Increments the reference counter. If necessary, executes the routine to deactivate the `referenced` flags, reorders the queue, and resets the counter. Removes the first element in the queue. Inserts the new page in sorted order.

#### Optimal Algorithm (Optimal)

Removes the page that will be referenced the furthest in the future. A queue structure, called `page_list`, is defined with a certain limit of elements, called `entry_max`. Each page has an entry called `next_ref`, which indicates the next line in which the page is referenced in the virtual address `file`. If there are no further references, the symbolic constant `PINF` (Page Index Not Found) is defined as the largest value representable by an unsigned integer, assumed to be larger than the number of lines in the file. The idea is that each time a page is referenced, the file is traversed until the next reference line is found, then it returns to the original position.

Thus, the pages are sorted in descending order by the line number of the next reference. In this way, pages referenced the furthest in the future are at the front, and the replacement is limited to removing the first element. If a page already in the queue is referenced, it is simply removed, its `next_ref` is updated, and it is reintegrated in sorted order.

Finally, it is worth mentioning that if two or more pages have no further references, the algorithm will first remove those that have not been modified, to reduce the number of writes to disk. In this case:

- If condition 1 occurs:
  Removes the page, updates its `next_ref` and other attributes, and reinserts it in sorted order.
- If condition 2.a occurs:
  Obtains the `next_ref` and simply inserts the page in sorted order.
- If condition 2.b occurs:
  Removes the first page from the queue and inserts the new page in sorted order.

### Tests

The tests were performed with four input `.log` files simulating different access patterns. Additionally, the page sizes (either 8 KB or 32 KB) and the main memory sizes (1 MB or 2 MB) were varied. A total of 32 [graphs](https://docs.google.com/spreadsheets/d/1HnZrXXxIdN1HFNX85y-cW_JEE9XiMo_xyHprkrHulz0/edit?usp=sharing) were generated.

### Observations and Conclusions

From the graphs, it can be observed that increasing the page size tends to increase the number of page faults, as the maximum number of pages in memory is reduced. By similar reasoning, increasing the size of the main memory while keeping the page size fixed tends to reduce the number of page faults.

Regarding the performance of the algorithms, it is clear that, as expected, the Optimal algorithm always resulted in the lowest number of page faults but, surprisingly, also in the fewest number of page writes. This last fact is due to the optimization implemented for dirty page replacement. Next, LRU seems to have generated the second lowest number of page faults, with NRU right behind it. Regarding page writes, the situation reverses between the two. After all, NRU has optimizations aimed at avoiding modified pages to be written. On the other hand, it is worth mentioning that using the LRU criterion as a tie-breaker for NRU caused the page fault rates of both algorithms to be similar in all situations. Finally, it can be seen that FIFO Second Chance produced the worst results in all aspects, indicating the ineffectiveness of the FIFO policy.

In light of the above, for future studies, it is suggested to explore hybrid or adaptive algorithms that combine the strengths of the approaches analyzed.
